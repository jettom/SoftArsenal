[MUSIC] In many situations, we need to
demonstrate validity of assertions. For example,
you are a venture capitalist and is proposed a project running 36 months. With 36 months data at hand,
should you invest in this project? Suppose you will invest if average
monthly profit is over 20,000. This question is not to ask you
to estimate some parameters. Instead, you need to make a judgement
whether the condition is satisfied. We need a new statistic tool,
hypothesis testing. This is a daily close price
of Apple from 2007 to 2018. It looks like the price
is in an upward trend and we may guess the average of
daily return is positive. However, if we plot
the daily return directly, the daily return goes positive, negative. And our assertion that the average of
daily return is positive is not obvious. It is also not obvious whether
the average of daily return is 0 or not. In the histogram daily return,
it is approximately symmetric above 0. It is still not obvious whether the
average daily return is different from 0. We want to use a quantitative
statistical tool to make judgement about the assertion that
the average daily return is not 0. In statistics, hypothesis testing
can use sample information to test the validity of conjectures
about these parameters. Let's start with hypothesis testing. The first step is to set hypothesis. We have null hypothesis and
alternative hypothesis. Usually, the null hypothesis
is assertion we are against. Alternative hypothesis is a conclusion
we accept whenever we reject the null. Hence in our example, the null is population mean,
the average daily return is 0. In alternative hypothesis,
average daily return is not equal to 0. Whether to reject or not reject null
hypothesis is a sample based decision. Intuitionally, given that the null is
correct, the difference between sample statistic, x-bar, and the population
parameter mu cannot be very large. If it's significantly large, the null should be incorrect,
and we should accept alternative. To measure the magnitude of difference,
we also need to consider the standard deviation of the sample, because
the sample with a large standard deviation usually its magnitude is larger,
hence we need to do standardization. If we know population standard deviation, the standardized sample mean we denote
as z-hat, and the z-distribution, if population is normal,
or it's sample size large. If a z-hat is far away from 0,
then null is not likely to be true. In hypothesis testing, we start with
assumption that the null is correct. Hence, we know population mean is equal to 0. But in most situations, population
standard deviation is not known. Then we can replace
population standard deviation with the sample standard deviation. Then this new term denoted as t-hat,
has a new distribution, t-distribution. Similar to z-distribution, t is a symmetric with respect to 0 and
a bell-shaped. The difference lies in the tail. T-distribution had flat
tails which implies t has a higher chance to take
the values in the two tails. The t-distribution is a dependent
on the degree of freedom. In our example, the degree of freedom
is equal to the degree of freedom of the sample standard deviation,
which is n-1. As the sample size increases,
the degree of freedom increases, and the t is more and
more like z-distribution. So with a large sample, we can treat
t as if it is a z-distribution. We will use a t-distribution
in next topic. With large sample, t-hat follows z-distribution hence we
denote this statistic using z-hat too. To emphasize that,
it follows z-distribution. We can compute z-hat using Python. X-bar is sample mean,
average daily return. S is sample standard deviation,
n is a sample size. Z-hat equal to 2.5897 It's
a standardized statistics. We use mu equal to 0 because we assume
the null is correct at the beginning. If z-hat is different from 0
significantly, we can infer that this sample is not sampled for
the population with mean equal to 0. Then, we can reject the null. How do we find the significance level? We use the probability on the two
tails of a z-distribution. we fixed the significance level,
for example, alpha equal to 5%, which is the probability for z to take the
values of some demands of the two tails? We can see that these
two demands is z less than -1.96 and z bigger 1.96. -1.96 and positive 1.96 are 2.5% and 97.5% quantiles of z. These two demands are called
rejection regions and this kind of test is
called two-tailed test. If statistic z-hat falls
into rejection region, we can tell that statistics
is far away from 0, significantly and
then we can reject the null. Here, we should notice that
z-hat is also possible to take values in rejection region even if the
null is correct, and the mu equal to 0. This chance is equal to alpha 5%. In other words, we have a 5% chance to reject null wrongly. This is called a type 1 error, and
the probability of a type 1 error is identical to the level
of significance level. If a significance level is small, the
probability of a type 1 error is smaller. Here, we demonstrate how
to get the quantiles which is also called critical values. Alpha equal to 5% is a given hence, norm.ppf can be applied
to get the quantiles. In the print, we use a bold number
to generate whether to reject or not directly. Hence, our final conclusion,
we will reject null hypothesis and the average daily return
is not equal to 0. Our conclusion may be wrong but
it happens only with 5% probability. We may want to further demonstrate that
the average return is in fact positive. We need another kind of test,
one-tail test. In one tail test, the null is
the average daily return is less than or equal to 0, which we are against. The alternative hypothesis,
the average daily return is positive. First, we take a mu equal to 0. We still need to standardize sample mean, which is average daily
return in the sample. If z-hat is significantly large, which implies that sample mean is
a positive comparing to mu equal to 0. Hence, it is not likely to be sampled
from population, which may equal to 0. It is also not likely to be sampled
from population with negative mu. Similarly, we fix
significance level alpha, and identify rejection region
using z-distribution, which is z-hat is larger than z-alpha. Using Python, we can show that
the null is rejected under 5%. It means that the average daily return
of a population is indeed positive. From this result, we do need
a quantitative statistic tool to validate our assertion in addition to
visualize the data. Conclusion, For population mean, we have these three kinds of
hypothesis in the regression criteria. For different kinds of hypothesis,
the criterion is different. A more popular way of testing
is to compute p-value. We know that given that null is correct, standardized sample mean
follows z-distribution. What is the probability for
this distribution to take a more extreme value than our
observation in given sample? This is a p-value, if p is less
than alpha which is a threshold, it means that the null
is unlikely to be true. With p-value,
we only need to compare it with alpha although the way to
compute p is different. Here's a demonstration
of p-value approach, in two-tailed test,
abs is to compute the absolute value. We use norm.cdf to
compute cumulative probability. In this video, we discussed another
quantitative tool which is applied to validate assertion about population. In next topic, we will use all
knowledge we learned in topic two and three to explore relationship
among different variables to build a prediction
model in stock market. And finally,
evaluate the performance of our models.